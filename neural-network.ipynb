{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "import scipy.io\n",
    "from scipy.special import expit #sigmoid function\n",
    "from scipy.stats import logistic #for sigmoid gradient\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = sorted(['alpha_lc', 'alpha_uc',\n",
    "               'beta_lc', 'beta_uc',\n",
    "               'gamma_lc', 'gamma_uc',\n",
    "               'delta_lc', 'delta_uc',\n",
    "               'epsilon_lc', 'epsilon_uc',\n",
    "               'zeta_lc', 'zeta_uc',\n",
    "               'eta_lc', 'eta_uc',\n",
    "               'theta_lc', 'theta_uc',\n",
    "               'iota_lc', 'iota_uc',\n",
    "               'kappa_lc', 'kappa_uc',\n",
    "               'lambda_lc', 'lambda_uc',\n",
    "               'mu_lc', 'mu_uc',\n",
    "               'nu_lc', 'nu_uc',\n",
    "               'xi_lc', 'xi_uc',\n",
    "               'omicron_lc', 'omicron_uc',\n",
    "               'pi_lc', 'pi_uc',\n",
    "               'rho_lc', 'rho_uc',\n",
    "               'sigma_lc', 'sigma_uc',\n",
    "               'tau_lc', 'tau_uc',\n",
    "               'upsilon_lc', 'upsilon_uc',\n",
    "               'phi_lc', 'phi_uc',\n",
    "               'chi_lc', 'chi_uc',\n",
    "               'psi_lc', 'psi_uc',\n",
    "               'omega_lc', 'omega_uc'\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, n_input, n_output, n_hidden=25, lambda_=0, epsilon=0.10, random_state=None, max_iter=1000):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.lambda_ = lambda_\n",
    "        self.epsilon = epsilon\n",
    "        np.random.seed(random_state)\n",
    "        self.max_iter = max_iter\n",
    "        self.theta1, self.theta2 = self._initialize_weights()\n",
    "\n",
    "    def _unroll_weights(self, theta1, theta2):\n",
    "        \"\"\"Unroll theta weights\n",
    "        (used for passing one weight name to the minimization function)\n",
    "        \"\"\"\n",
    "        theta1 = theta1.reshape(theta1.size,order='F')\n",
    "        theta2 = theta2.reshape(theta2.size,order='F')\n",
    "        weights = np.concatenate((theta1, theta2), axis=0)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def _reshape_weights(self, weights):\n",
    "        \"\"\"Reshape weights to theta1, theta2 names (opposite of _unroll_weights())\n",
    "        \"\"\"\n",
    "\n",
    "        theta1 = np.reshape(weights[0:(self.n_hidden)*(self.n_input+1)], (self.n_hidden, self.n_input+1), order=\"F\")\n",
    "        theta2 = np.reshape(weights[(self.n_hidden)*(self.n_input+1):], (self.n_output, self.n_hidden+1), order=\"F\")\n",
    "        \n",
    "        return theta1, theta2\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initiliaze weights for theta1 and theta2 by a random number in range [-epsilon,epsilon]\n",
    "        theta1 is of size hidden_layer x input_layer+1\n",
    "        theta2 is of size output_layer x hidden_layer+1\n",
    "        +1 is for the bias unit\n",
    "        \"\"\"\n",
    "        theta1 = np.random.rand(self.n_hidden, self.n_input+1) * 2 * self.epsilon - self.epsilon\n",
    "        theta2 = np.random.rand(self.n_output, self.n_hidden+1) * 2 * self.epsilon - self.epsilon\n",
    "\n",
    "        return theta1, theta2\n",
    "    \n",
    "    def _propagate_forward(self, X, theta1, theta2):\n",
    "        \"\"\"Perform feed forward process of neural network\"\"\"\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        a1 = np.concatenate((np.ones((m,1)), X), axis=1)\n",
    "        z2 = a1.dot(theta1.T)\n",
    "        a2 = expit(z2)\n",
    "        a2 = np.concatenate((np.ones((m,1)), a2), axis=1)\n",
    "        z3 = a2.dot(theta2.T)\n",
    "        a3 = expit(z3)\n",
    "        \n",
    "        return a1, z2, a2, a3, z3\n",
    "    \n",
    "    def _propagate_backward(self, weights, a1, z2, a2, a3, y):\n",
    "        \"\"\"Perform backpropagation\"\"\"\n",
    "        m = y.shape[0]\n",
    "        theta1, theta2 = self._reshape_weights(weights)\n",
    "\n",
    "        d3 = a3 - y\n",
    "        d2 = np.dot(d3,theta2[:,1:])\n",
    "        d2 = np.multiply(d2,logistic._pdf(z2)) #logistic._pdf is the gradient of the sigmoid function\n",
    "\n",
    "        Delta1 = np.dot(d2.T,a1)\n",
    "        Delta2 = np.dot(d3.T,a2)\n",
    "\n",
    "        # set first columns to 0 to not have an effect in regularization\n",
    "        theta1[:,0] = 0\n",
    "        theta2[:,1] = 0\n",
    "\n",
    "        theta1_grad = 1/m * (Delta1 + (self.lambda_*theta1))\n",
    "        theta2_grad = 1/m * (Delta2 + (self.lambda_*theta2))\n",
    "\n",
    "        grad = self._unroll_weights(theta1_grad, theta2_grad)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def _compute_cost(self, weights, X, y):\n",
    "        \"\"\"Return cost and gradient for X, y\n",
    "        \n",
    "        Performs forward propagation, computes the unregularized cost and executes backward propagation to get gradients\n",
    "        \"\"\"\n",
    "        m = X.shape[0]\n",
    "        J = 0\n",
    "\n",
    "        theta1, theta2 = self._reshape_weights(weights)\n",
    "\n",
    "        a1, z2, a2, a3, z3 = self._propagate_forward(X, theta1, theta2)\n",
    "\n",
    "        J_unreg = 1/m * (np.sum((np.multiply(-y,np.log(a3)) - (np.multiply((1-y),np.log(1-a3))))))\n",
    "        J = J_unreg + (self.lambda_/(2*m) * ((np.sum(np.square(theta1[:,1:]))) + (np.sum(np.square(theta2[:,1:])))))\n",
    "\n",
    "        grad = self._propagate_backward(weights, a1, z2, a2, a3, y)\n",
    "        \n",
    "        return (J, grad)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        weights = self._unroll_weights(self.theta1, self.theta2)\n",
    "\n",
    "        result = scipy.optimize.minimize(fun=self._compute_cost, x0=weights, args=(X, y), method='CG', jac=True, options={'maxiter': self.max_iter, 'disp': True})        \n",
    "        \n",
    "        self.theta1, self.theta2 = self._reshape_weights(result.x)\n",
    "        \n",
    "        print('Cost in final computation: %f' % result.fun)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return index of predicted class (highest probability) and array of prediction scores for all classes\"\"\"\n",
    "        a1, z2, a2, a3, z3 = self._propagate_forward(X, self.theta1, self.theta2)\n",
    "        p = a3.argmax(axis=1)\n",
    "\n",
    "        return p, a3\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save learned weights to make them available for the web app\"\"\"\n",
    "        np.save('theta1.npy', self.theta1)\n",
    "        np.save('theta2.npy', self.theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_layer_size = 48 #24 in lowercase and 24 in uppercase\n",
    "\n",
    "# load drawings\n",
    "X = np.load('pixel_data.npy')\n",
    "y_data = np.load('label_data.npy')\n",
    "y = np.eye(output_layer_size)[y_data[:]] # make mxn matrix (for each row value in y, select the corresponding row of the eye matrix)\n",
    "\n",
    "neural_net = NeuralNet(n_input = 400,\n",
    "                       n_output = output_layer_size,\n",
    "                       n_hidden = 45,\n",
    "                       lambda_ = 2,\n",
    "                       max_iter = 3000,\n",
    "                       epsilon = 0.15,\n",
    "                       random_state = 9\n",
    "                      )\n",
    "neural_net.fit(X, y)\n",
    "neural_net.save() # write out learned weights for the web app to use for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions, scores = neural_net.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]\n",
    "print('Training accuracy: ', sum(predictions==y_data)*100 / m, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose a random letter, display and show predictions\n",
    "\n",
    "index = np.random.randint(0,X.shape[0],1)\n",
    "x = X[index]\n",
    "x_predict = neural_net.predict(x)[0]\n",
    "w, h = 20, 20\n",
    "image = x.reshape(w,h)\n",
    "\n",
    "x_predict_label = alphabet[int(x_predict)]\n",
    "x_actual_label = alphabet[y[index].argmax()]\n",
    "\n",
    "print('Predicted %s, labelled as %s' % (x_predict_label, x_actual_label))\n",
    "plt.imshow(image,cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer visualization\n",
    "# enable for debugging\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize=(10, 10), dpi=200)\n",
    "for i,e in enumerate(neural_net.theta1):\n",
    "    a=fig.add_subplot(5,5,i+1)\n",
    "    image = e[1:].reshape(w,h)\n",
    "    plt.imshow(image, cmap='gray_r')\n",
    "plt.show\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random misclassification, display and show predictions\n",
    "\n",
    "failures = np.asarray(np.where(predictions!=y_data)[0])\n",
    "index = np.random.randint(0,failures.shape[0],1)\n",
    "index = failures[index]\n",
    "x = X[index]\n",
    "image = x.reshape(w,h)\n",
    "x_predict, x_predict_scores = neural_net.predict(x)\n",
    "x_predict_label = alphabet[int(x_predict)]\n",
    "x_actual_label = alphabet[y[index].argmax()]\n",
    "\n",
    "print('Predicted %s, labelled as %s\\n' % (x_predict_label, x_actual_label))\n",
    "\n",
    "results = []\n",
    "for i, score in enumerate(x_predict_scores.T):\n",
    "    results.append([alphabet[i], score])\n",
    "\n",
    "# show predictions, confidence value descending\n",
    "for result in sorted(results,key=lambda x: float(x[1]), reverse=True):\n",
    "    print(result[0], '_______', result[1][0])\n",
    "\n",
    "plt.imshow(image,cmap='gray_r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
